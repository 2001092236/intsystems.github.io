### О курсе
Курс посвящен современным генеративным моделям машинного обучения.
Особое внимание уделяется свойствам различных классов генеративных моделей, их взаимосвязям, теоретическим предпосылкам и методам оценки качества.
Цель курса - познакомить студента с широко используемыми передовыми методами построения порождающих моделей.

### Тематический план
1. Введение в генеративное моделирование. Постановка задачи. Задача минимизации дивергенций. Авторегрессионное моделирование.
2. Авторегрессионные модели (WaveNet, PixelCNN). Основы байесовского вывода. Модели скрытых переменных. Вариационная нижняя оценка (ELBO). 
3. EM-алгоритм, амортизированный вывод. Градиенты ELBO, репараметризация. Вариационный автокодировщик (VAE). 
4. Недостатки VAE. Коллапс апостериорного распределения VAE. Техники ослабления декодера. Выборка по значимости для ELBO. Якобиан и теорема о замене переменных.
5. Модели нормализующих потоков. Прямая и обратная KL дивергенции. Линейные потоки (Glow). 
6. Авторегрессионные потоки (гауссовский и обраный гауссовский поток). Слой связи (RealNVP). Связь нормализующих потоков и VAE. 
7. Дискретные данные, непрерывная модель. Дискретизация модели (PixelCNN++). Равномерная и вариационная деквантизации (Flow++). Теорема об операции над ELBO. Оптимальное априорное распределение в VAE. Потоки в априорном распределении VAE. 
8. Потоки в априорном и апостериорном распределении VAE. Неявные генеративные модели без оценки правдоподобия. Модель генеративных состязательных сетей (GAN). Теорема об оптимальности GAN.
9. Проблемы обучения GAN моделей (затухающие градиенты, коллапс мод). KL дивергенция vs JS дивергенция. VAE с неявным энкодером. Топологические особенности обучения GAN моделей. Расстояние Вассерштейна. Дуальность Канторовича-Рубинштейна. GAN Вассерштейна (WGAN). 
10. Модель WGAN с градиентным штрафом. Модель WGAN со спектральной нормализацией. Вариационная минимизация f-дивергенций. Оценивание качества неявных моделей.
11. Оценивание качества неявных моделей (Inception score, FID, Precision-Recall, truncation trick). VAE с дискретным скрытым пространством. 
12. Векторная квантизация, сквозной градиент (VQ-VAE). Гумбель-софтмакс трюк (DALL-E). Нейронные обыкновенные дифференциальные уравнения. Метод сопряженных функций.
13. Непрерывные во времени нормализационные потоки (FFJORD). Несмещенная оценка следа матрицы. Основы стохастических дифференциальных уравнений. Уравнение Колмогорова-Фоккера-Планка и динамика Ланжевена. Методы оценивания score функции.
14. Модели оценки score функции (NCSM). Гауссовский диффузионый процесс. Диффузионная генеративная модель (DDPM).

### Cамостоятельная работа
6 домашних работ, каждая содержит как теоретические задания, так и практические.

### Оценивание
Каждая домашняя работа дает 13 баллов + экзамен на 26 баллов. Финальная оценка: (количество баллов / 8) - 2.

### Требуемые знания
Статистика, машинное обучение, глубокое обучение, элементы байесовского вывода.
